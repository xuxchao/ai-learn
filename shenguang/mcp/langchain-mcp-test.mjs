import 'dotenv/config';
import { MultiServerMCPClient } from '@langchain/mcp-adapters';
import { ChatOpenAI } from '@langchain/openai';
import chalk from 'chalk';
import { HumanMessage, ToolMessage, SystemMessage } from '@langchain/core/messages';

const model = new ChatOpenAI({
    modelName: process.env.MODEL_NAME || "qwen-plus",
    apiKey: process.env.OPENAI_API_KEY,
    temperature: 0,
    configuration: {
        baseURL: process.env.BASE_URL,
    },
});

const mcpClient = new MultiServerMCPClient({
    mcpServers: {
        'my-mcp-server': {
            command: "node",
            args: [
                "D:\\my\\ai-learn\\shenguang\\mcp\\server.mjs"
            ]
        },
        "amap-maps-streamableHTTP": {
            "url": "https://mcp.amap.com/mcp?key=" + process.env.AMAP_API_KEY
        },
        "filesystem": {
            "command": "npx",
            "args": [
                "-y",
                "@modelcontextprotocol/server-filesystem",
                ...(process.env.ALLOWED_PATHS.split(',') || '')
            ]
        },
        "chrome-devtools": {
            "command": "npx",
            "args": [
                "-y",
                "chrome-devtools-mcp@latest"
            ]
        }
    }
});

const tools = await mcpClient.getTools();
console.log(chalk.bgGreen('mcp æœåŠ¡è·å–æˆåŠŸ'))
// constÂ res =Â awaitÂ mcpClient.listResources();
// console.log('æŸ¥çœ‹ mcp ä¿¡æ¯', res);

const res = await mcpClient.listResources();

let resourceContent = '';
for (const [serverName, resources] of Object.entries(res)) {
    for (const resource of resources) {
        const content = await mcpClient.readResource(serverName, resource.uri);
        resourceContent += content[0].text;
    }
}

const modelWithTools = model.bindTools(tools);

async function runAgentWithTools(query, maxIterations = 30) {
    const messages = [
        new SystemMessage(resourceContent),
        new HumanMessage(query)
    ];

    for (let i = 0; i < maxIterations; i++) {
        console.log(chalk.bgGreen(`â³ æ­£åœ¨ç­‰å¾… AI æ€è€ƒ...`));
        const response = await modelWithTools.invoke(messages);
        messages.push(response);

        // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        if (!response.tool_calls || response.tool_calls.length === 0) {
            console.log(`\nâœ¨ AI æœ€ç»ˆå›å¤:\n${response.content}\n`);
            return response.content;
        }

        console.log(chalk.bgBlue(`ğŸ” æ£€æµ‹åˆ°Â ${response.tool_calls.length}Â ä¸ªå·¥å…·è°ƒç”¨`));
        console.log(chalk.bgBlue(`ğŸ” å·¥å…·è°ƒç”¨:Â ${response.tool_calls.map(t => t.name).join(', ')}`));
        // æ‰§è¡Œå·¥å…·è°ƒç”¨
        for (const toolCall of response.tool_calls) {
            const foundTool = tools.find(t => t.name === toolCall.name);
            if (foundTool) {
                const toolResult = await foundTool.invoke(toolCall.args);


                // ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²ç±»å‹
                let contentStr;
                if (typeof toolResult === 'string') {
                    contentStr = toolResult;
                } else if (toolResult && toolResult.text) {
                    // å¦‚æœè¿”å›å¯¹è±¡æœ‰ text å­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨
                    contentStr = toolResult.text;
                }

                messages.push(new ToolMessage({
                    content: contentStr,
                    tool_call_id: toolCall.id,
                }));
            }
        }
    }

    return messages[messages.length - 1].content;
}

// await runAgentWithTools("åŒ—äº¬å—ç«™é™„è¿‘çš„5ä¸ªé…’åº—ï¼Œä»¥åŠå»çš„è·¯çº¿ï¼Œè·¯çº¿è§„åˆ’ç”Ÿæˆæ–‡æ¡£ä¿å­˜åˆ° D:\\my\\ai-learn\\shenguang\\mcp çš„ä¸€ä¸ª md æ–‡ä»¶");

awaitÂ runAgentWithTools("åŒ—äº¬å—ç«™é™„è¿‘çš„é…’åº—ï¼Œæœ€è¿‘çš„ 3 ä¸ªé…’åº—ï¼Œæ‹¿åˆ°é…’åº—å›¾ç‰‡ï¼Œæ‰“å¼€æµè§ˆå™¨ï¼Œå±•ç¤ºæ¯ä¸ªé…’åº—çš„å›¾ç‰‡ï¼Œæ¯ä¸ª tab ä¸€ä¸ª url å±•ç¤ºï¼Œå¹¶ä¸”åœ¨æŠŠé‚£ä¸ªé¡µé¢æ ‡é¢˜æ”¹ä¸ºé…’åº—å");


// awaitÂ runAgentWithTools("MCP Server çš„ä½¿ç”¨æŒ‡å—æ˜¯ä»€ä¹ˆ");


await mcpClient.close()
