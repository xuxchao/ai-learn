require('dotenv').config();
const OpenAI = require('openai');

class HelloAgentsLLM {
  /**
   * ä¸ºæœ¬ä¹¦ "Hello Agents" å®šåˆ¶çš„LLMå®¢æˆ·ç«¯ã€‚
   * å®ƒç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ï¼Œå¹¶é»˜è®¤ä½¿ç”¨æµå¼å“åº”ã€‚
   */
  constructor(config = {}) {
    /**
     * åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚
     */
    this.model = config.model || process.env.LLM_MODEL_ID;
    const apiKey = config.apiKey || process.env.LLM_API_KEY;
    const baseUrl = config.baseUrl || process.env.LLM_BASE_URL;
    const timeout = config.timeout || parseInt(process.env.LLM_TIMEOUT || 60, 10);

    if (!this.model || !apiKey || !baseUrl) {
      throw new Error('æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚');
    }

    this.client = new OpenAI({
      apiKey,
      baseURL: baseUrl,
      timeout,
    });
  }

  /**
   * è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚
   * @param {Array<{role: string, content: string}>} messages - æ¶ˆæ¯æ•°ç»„
   * @param {number} temperature - æ¸©åº¦å‚æ•°
   * @returns {Promise<string|null>}
   */
  async think(messages, temperature = 0) {
    console.log(`ğŸ§  æ­£åœ¨è°ƒç”¨ ${this.model} æ¨¡å‹...`);

    try {
      const stream = await this.client.chat.completions.create({
        model: this.model,
        messages,
        temperature,
        stream: true,
      });

      console.log('âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:');
      let collectedContent = '';

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content || '';
        process.stdout.write(content);
        collectedContent += content;
      }
      console.log(); // åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ

      return collectedContent;
    } catch (error) {
      console.log(`âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: ${error.message}`);
      return null;
    }
  }
}

// --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---
async function main() {
  try {
    const llmClient = new HelloAgentsLLM();

    const exampleMessages = [
      { role: 'system', content: 'You are a helpful assistant that writes js code.' },
      { role: 'user', content: 'å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•' },
    ];

    console.log('--- è°ƒç”¨LLM ---');
    const responseText = await llmClient.think(exampleMessages);

    if (responseText) {
      console.log('\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---');
      console.log(responseText);
    }
  } catch (error) {
    console.log(error.message);
  }
}

module.exports = HelloAgentsLLM;

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶
if (require.main === module) {
  main();
}
